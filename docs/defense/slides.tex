\documentclass[aspectratio=169]{beamer}
\graphicspath{{graphics/}}

\usetheme[progressbar=frametitle]{metropolis}
\usepackage{FiraSans}
\usepackage[style=apa]{biblatex}

\setbeamertemplate{caption}{\raggedright\insertcaption\par}

\renewcommand*{\bibfont}{\footnotesize}
\setbeamertemplate{bibliography item}{}
\addbibresource{bibliography.bib}

\title{Acceleration by Separate-Process Cache\\for Memory-Intensive Algorithms
on FPGA\\via High-Level Synthesis}
\subtitle{Master's Degree Thesis}
\author{Brignone Giovanni \\ \tiny{Supervisor:} \small{Prof.\ Lavagno Luciano}}
\titlegraphic{\hfill\includegraphics[height=2cm]{logopolitonuovo}}
\institute{Politecnico di Torino}
\date{October 21, 2021}

\begin{document}
\begin{frame}
	\maketitle
\end{frame}

%\begin{frame}{Outline}
%	\setbeamertemplate{section in toc}[sections numbered]
%	\tableofcontents[hideallsubsections]
%\end{frame}

{
	\metroset{sectionpage=none}
	\section{Introduction}
}
\begin{frame}{High-Level Synthesis}
	\begin{columns}[c]
		\begin{column}{.45\textwidth}
			\begin{center}
				\includegraphics[height=.6\textheight]{hls}
			\end{center}
		\end{column}
		\begin{column}{.05\textwidth}
			\begin{center}
				\includegraphics[width=0.7cm]{arrow}
			\end{center}
		\end{column}
		\begin{column}{.45\textwidth}
			\textbf{Productivity}:
			\begin{itemize}
				\item Functionality
				\item Debugging
				\item Design space exploration
			\end{itemize}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}{Memory management}
	\begin{columns}[c]
		\begin{column}{.55\textwidth}
			\textbf{Scratchpad}:
			\begin{itemize}
				\item Manual memory selection
				\item HLS state of the art
			\end{itemize}

			\bigskip

			\textbf{Cache}:
			\begin{itemize}
				\item Automatically exploit whole hierarchy
				\item<alert@+> Thesis work objective
			\end{itemize}
		\end{column}
		\begin{column}{.5\textwidth}
			\begin{center}
				\includegraphics[width=.9\textwidth]{mem_hierarchy}
			\end{center}
		\end{column}
	\end{columns}
\end{frame}

\subsection{Previous work}
\begin{frame}{Previous work}
	\begin{columns}[c]
		\begin{column}{.55\textwidth}
			\vfill
			\textbf{Architecture}:
			\begin{itemize}
				\item Cache inlined in application
				\item One cache per DRAM array
			\end{itemize}

			\textbf{Implementation}:
			\begin{itemize}
				\item \texttt{C++} class
				\item {User friendliness}
					\begin{itemize}
						\item \emph{Integrability}: \texttt{operator[]} overload
						\item \emph{Configurability}: template parameters
						\item \emph{Observability}: hit ratio reports
					\end{itemize}
				\item Application logic cluttering
			\end{itemize}
		\end{column}
		\begin{column}{.5\textwidth}
			\begin{center}
				\includegraphics[height=.5\textheight]{liang_arch}
			\end{center}
		\end{column}
	\end{columns}
\end{frame}

\section{Thesis work}
\subsection{Basic architecture}
\begin{frame}{Basic architecture}
	\begin{columns}[c]
		\begin{column}{.55\textwidth}
			\textbf{Objective}:
			\begin{itemize}
				\item Limit application cluttering
			\end{itemize}

			\bigskip
			\textbf{Proposed solution}:
			\begin{itemize}
				\item \emph{Cache:} separate process
					\begin{itemize}
						\item Modeling: threads (SW), dataflow (HW)
						\item Communication: FIFOs
					\end{itemize}
				\item \emph{Application:}
					\begin{enumerate}
						\item Send \emph{request}
						\item Receive \emph{response}
					\end{enumerate}
			\end{itemize}
		\end{column}
		\begin{column}{.5\textwidth}
			\begin{center}
			\includegraphics[height=.7\textheight]{complete_arch}
			\end{center}
		\end{column}
	\end{columns}
\end{frame}
\begin{frame}{Basic architecture --- Implementation}
	\begin{columns}[c]
		\begin{column}{.55\textwidth}
			\vfill
			\textbf{Objective}:
			\begin{itemize}
				\item Optimally pipeline cache hits (II=1)
			\end{itemize}

			\bigskip
			\textbf{Problem}:
			\begin{itemize}
				\item Dependencies on DRAM interface
			\end{itemize}

			\bigskip
			\textbf{Proposed solution}:
			\begin{itemize}
				\item Multi-process architecture:
					\begin{itemize}
						\item \emph{Core}: cache functionality
						\item \makebox[\linewidth][l]{\emph{Memory interface}: DRAM accesses (miss only)}
					\end{itemize}
			\end{itemize}
		\end{column}
		\begin{column}{.5\textwidth}
			\begin{center}
			\includegraphics[height=.7\textheight]{multi_proc_basic_arch}
			\end{center}
		\end{column}
	\end{columns}
\end{frame}

\iffalse
\begin{frame}{Basic architecture}
	\begin{columns}[c]
		\begin{column}{.5\textwidth}
			\textbf{Cache process}:
			\begin{itemize}
				\item Optimal pipeline (II=1)
			\end{itemize}
			
			\bigskip
			\textbf{Interface}:
			\begin{itemize}
				\item Scheduler unaware of latency between
					\emph{request} and \emph{response}
				\item Workaround: forced clock cycles
			\end{itemize}
		\end{column}
		\begin{column}{.5\textwidth}
			\begin{center}
				\begin{figure}
					\caption{Original scheduling}
					\frame{\includegraphics[width=.55\textwidth]{actual_schedule_run}}
				\end{figure}
				\begin{figure}
					\caption{Scheduling with workaround}
					\frame{\includegraphics[width=.55\textwidth]{desired_schedule_run}}
				\end{figure}
			\end{center}
		\end{column}
	\end{columns}
\end{frame}
\fi

\section{Optimizations}
\subsection{Multi-levels architecture}
\begin{frame}{Multi-levels architecture}
	\begin{columns}[c]
		\begin{column}{.55\textwidth}
			\textbf{Objective}:
			\begin{itemize}
				\item Reduce read latency
			\end{itemize}
			
			\bigskip
			\textbf{Proposed solution}:
			\begin{itemize}
				\item L1 cache inlined in application
					\begin{itemize}
						\item Fast: no communication overhead
						\item Simple: direct mapped, write-through
					\end{itemize}
			\end{itemize}
		\end{column}
		\begin{column}{.5\textwidth}
			\begin{center}
			\includegraphics[height=.7\textheight]{l1_arch}
			\end{center}
		\end{column}
	\end{columns}
\end{frame}
\subsection{Multi-ports architecture}
\begin{frame}{Multi-ports architecture}
	\begin{columns}[c]
		\begin{column}{.55\textwidth}
			\textbf{Objective}:
			\begin{itemize}
				\item Execute multiple reads in parallel
			\end{itemize}

			\bigskip
			\textbf{Proposed solution}:
			\begin{itemize}
				\item Single L2 cache (with multiple ports)
				\item Multiple L1 caches (one per L2 port)
			\end{itemize}
		\end{column}
		\begin{column}{.5\textwidth}
			\begin{center}
			\includegraphics[height=.7\textheight]{multi_ports_arch}
			\end{center}
		\end{column}
	\end{columns}
\end{frame}

\section{Results}
\begin{frame}{Matrix multiplication}
	\begin{columns}[c]
		\begin{column}{.5\textwidth}
			\textbf{Algorithm}:
			\[C = A \times B, \quad A, B, C \in \mathbb{R}^{32 \times 32}\]

			\textbf{Caches configuration}:
			\begin{itemize}
				\item $A$: 1 line of 32 elements
				\item $B$: 32 lines of 32 elements
				\item $C$: 1 line of 32 elements
			\end{itemize}
		\end{column}
		\begin{column}{.5\textwidth}
			\begin{center}
				\includegraphics<1>[width=\textwidth]{plot}
				\includegraphics<2>[width=\textwidth]{plot-circle}
			\end{center}
		\end{column}
	\end{columns}
\end{frame}

\section{Summary}
\begin{frame}{Summary}
	\textbf{Achieved results}:
	\begin{itemize}
		\item Multi-process modeling for HLS
		\item Design space extended by cache
	\end{itemize}

	\bigskip
	\textbf{Future work}:
	\begin{itemize}
		\item RTL implementation
		\item Pre-fetching
	\end{itemize}
\end{frame}

\begin{frame}{References}
	\nocite{*}
	\printbibliography[heading=none]
\end{frame}

\end{document}

